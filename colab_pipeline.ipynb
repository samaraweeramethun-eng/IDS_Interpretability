{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98b23ea",
   "metadata": {},
   "source": [
    "# Methun Research — CNN-Transformer IDS with XAI\n",
    "\n",
    "This notebook runs the **full pipeline** on Google Colab or a GCE VM:\n",
    "\n",
    "| Step | What happens |\n",
    "|------|-------------|\n",
    "| **1. Setup** | Clone repo, install NVIDIA drivers + CUDA + deps, verify GPU |\n",
    "| **2. Data** | Upload / mount CICIDS2017 dataset |\n",
    "| **3. CNN-Transformer Training** | Train the hybrid model (+ IG & Grad-CAM) |\n",
    "| **4. Enhanced Transformer Training** | Train the grouped-token model |\n",
    "| **5. SHAP** | GradientExplainer feature importance + plots |\n",
    "| **6. Test Evaluation** | Held-out test set metrics (20 % unseen data) |\n",
    "| **7. Results** | Display all XAI outputs side by side |\n",
    "\n",
    "> **Colab:** Select **GPU → T4** via *Runtime → Change runtime type* before running.  \n",
    "> **GCE VM:** See the **VM Quick-Start** section below, or just run `vm_setup.sh` via SSH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db312af2",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. VM Quick-Start (skip this on Colab)\n",
    "\n",
    "If you're running on a **fresh GCE VM**, create it with the `gcloud` command below,\n",
    "then SSH in and run the setup script. Skip to **Step 2 (Data)** after setup.\n",
    "\n",
    "```bash\n",
    "# ── Create a GCE Spot VM with T4 GPU (~$0.11/hr) ────────────────\n",
    "gcloud compute instances create ids-training \\\n",
    "    --zone=us-central1-a \\\n",
    "    --machine-type=n1-standard-8 \\\n",
    "    --accelerator=type=nvidia-tesla-t4,count=1 \\\n",
    "    --maintenance-policy=TERMINATE \\\n",
    "    --provisioning-model=SPOT \\\n",
    "    --boot-disk-size=100GB \\\n",
    "    --image-family=ubuntu-2204-lts \\\n",
    "    --image-project=ubuntu-os-cloud \\\n",
    "    --metadata=startup-script='#!/bin/bash\n",
    "echo \"VM ready. SSH in and run vm_setup.sh\"'\n",
    "\n",
    "# ── SSH into the VM ──────────────────────────────────────────────\n",
    "gcloud compute ssh ids-training --zone=us-central1-a\n",
    "\n",
    "# ── Run the setup script (installs drivers, CUDA, Python, repo) ─\n",
    "curl -sL https://raw.githubusercontent.com/samaraweeramethun-eng/IDS_Interpretability/main/vm_setup.sh | bash\n",
    "\n",
    "# ── Upload your dataset ─────────────────────────────────────────\n",
    "# From your LOCAL machine:\n",
    "gcloud compute scp cicids2017.csv ids-training:~/IDS_Interpretability/data/cicids2017/ --zone=us-central1-a\n",
    "\n",
    "# ── Run the full pipeline (headless, ~65 min on T4) ─────────────\n",
    "cd ~/IDS_Interpretability && source .venv/bin/activate\n",
    "python scripts/run_full_pipeline.py --data data/cicids2017/cicids2017.csv\n",
    "\n",
    "# ── Download results ─────────────────────────────────────────────\n",
    "# From your LOCAL machine:\n",
    "gcloud compute scp --recurse ids-training:~/IDS_Interpretability/artifacts/ ./artifacts/ --zone=us-central1-a\n",
    "\n",
    "# ── Delete VM when done ──────────────────────────────────────────\n",
    "gcloud compute instances delete ids-training --zone=us-central1-a\n",
    "```\n",
    "\n",
    "---\n",
    "## 1. Setup — Clone & Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, subprocess\n",
    "\n",
    "# ── Detect environment ───────────────────────────────────────────────\n",
    "IN_COLAB = 'google.colab' in sys.modules or os.path.exists('/content')\n",
    "IN_VM = not IN_COLAB\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'VM / Local'}\")\n",
    "\n",
    "# ── Install NVIDIA driver + CUDA if needed (VM only) ────────────────\n",
    "if IN_VM and not os.path.exists('/usr/local/cuda'):\n",
    "    print(\"Installing NVIDIA driver + CUDA 12.1 (this takes a few minutes)...\")\n",
    "    cmds = [\n",
    "        \"sudo apt-get update -qq\",\n",
    "        \"sudo apt-get install -y -qq build-essential curl wget\",\n",
    "        \"wget -q https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb -O /tmp/cuda-keyring.deb\",\n",
    "        \"sudo dpkg -i /tmp/cuda-keyring.deb\",\n",
    "        \"sudo apt-get update -qq\",\n",
    "        \"sudo apt-get install -y -qq cuda-toolkit-12-1 cuda-drivers\",\n",
    "    ]\n",
    "    for cmd in cmds:\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    os.environ['PATH'] = '/usr/local/cuda-12.1/bin:' + os.environ.get('PATH', '')\n",
    "    os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-12.1/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "    print(\"✓ CUDA installed\")\n",
    "\n",
    "# ── Clone repository ─────────────────────────────────────────────────\n",
    "REPO_DIR = '/content/IDS_Interpretability' if IN_COLAB else os.path.expanduser('~/IDS_Interpretability')\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/samaraweeramethun-eng/IDS_Interpretability.git {REPO_DIR}\n",
    "else:\n",
    "    print(f\"Repo exists at {REPO_DIR} — pulling latest...\")\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# ── Install PyTorch + dependencies ───────────────────────────────────\n",
    "!pip install -q torch --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q -e .\n",
    "!pip install -q psutil\n",
    "\n",
    "# ── Fallback: add src/ to sys.path ───────────────────────────────────\n",
    "SRC_DIR = os.path.join(os.getcwd(), 'src')\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "# ── Verify ───────────────────────────────────────────────────────────\n",
    "import methun_research\n",
    "print(f\"\\n✓ methun_research imported from: {methun_research.__file__}\")\n",
    "\n",
    "import torch\n",
    "print(f\"✓ PyTorch {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f\"✓ VRAM: {total/1024**3:.1f} GB total, {free/1024**3:.1f} GB free\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: No GPU detected — training will be very slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9ea9f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data — Load CICIDS2017\n",
    "\n",
    "Choose **one** of the options below:\n",
    "\n",
    "- **Option A:** Mount Google Drive (Colab)  \n",
    "- **Option B:** Upload a CSV interactively (Colab)  \n",
    "- **Option C:** Copy from GCS bucket (VM — `gsutil cp`)  \n",
    "- **Option D:** SCP from local machine (VM — `gcloud compute scp`)  \n",
    "- **Option E (default):** Use the included 5 000-row sample for a quick smoke test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ── Option A: Mount Google Drive (Colab only) ───────────────────────\n",
    "# Uncomment if your dataset is on Google Drive.\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "# DRIVE_CSV = '/content/drive/MyDrive/cicids2017/cicids2017.csv'\n",
    "# !mkdir -p data/cicids2017\n",
    "# !ln -sf \"$DRIVE_CSV\" data/cicids2017/cicids2017.csv\n",
    "\n",
    "# ── Option B: Upload from local machine (Colab only) ────────────────\n",
    "# Uncomment to upload interactively.\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # select your cicids2017.csv\n",
    "# !mkdir -p data/cicids2017\n",
    "# !mv \"{list(uploaded.keys())[0]}\" data/cicids2017/cicids2017.csv\n",
    "\n",
    "# ── Option C: GCS bucket (VM recommended) ───────────────────────────\n",
    "# Uncomment and fill in your bucket name.\n",
    "\n",
    "# !gsutil cp gs://YOUR_BUCKET/cicids2017.csv data/cicids2017/cicids2017.csv\n",
    "\n",
    "# ── Option D: SCP (VM) ──────────────────────────────────────────────\n",
    "# From your LOCAL machine run:\n",
    "#   gcloud compute scp cicids2017.csv ids-training:~/IDS_Interpretability/data/cicids2017/ --zone=us-central1-a\n",
    "\n",
    "# ── Auto-detect dataset ─────────────────────────────────────────────\n",
    "DATA_PATH = 'data/cicids2017/cicids2017_sample.csv'\n",
    "if os.path.exists('data/cicids2017/cicids2017.csv'):\n",
    "    DATA_PATH = 'data/cicids2017/cicids2017.csv'\n",
    "\n",
    "print(f'Using dataset: {DATA_PATH}')\n",
    "print(f'Size: {os.path.getsize(DATA_PATH) / 1024**2:.1f} MB')\n",
    "\n",
    "import pandas as pd\n",
    "df_peek = pd.read_csv(DATA_PATH, nrows=5)\n",
    "print(f'Columns: {len(df_peek.columns)}')\n",
    "label_col = [c for c in df_peek.columns if 'label' in c.lower()][0]\n",
    "counts = pd.read_csv(DATA_PATH, usecols=[label_col])[label_col].value_counts()\n",
    "print(f'\\nLabel distribution:\\n{counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f43e2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configure Training\n",
    "\n",
    "Adjust hyperparameters below. The defaults are tuned for a **T4 GPU** with the full dataset.  \n",
    "If you are using the 5 000-row sample, the `_sample` overrides will automatically apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure methun_research is importable (survives kernel restart)\n",
    "SRC_DIR = os.path.join(os.getcwd(), 'src')\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from methun_research.config import CNNTransformerConfig, EnhancedConfig\n",
    "\n",
    "USE_SAMPLE = 'sample' in DATA_PATH\n",
    "\n",
    "# ── CNN-Transformer Config (optimised for T4 GPU) ────────────────────\n",
    "cnn_cfg = CNNTransformerConfig(\n",
    "    input_path=DATA_PATH,\n",
    "    output_dir='artifacts',\n",
    "    epochs=25 if not USE_SAMPLE else 5,\n",
    "    batch_size=1024 if not USE_SAMPLE else 64,\n",
    "    val_batch_size=2048 if not USE_SAMPLE else 128,\n",
    "    lr=2e-3 if not USE_SAMPLE else 1.5e-3,\n",
    "    num_workers=2,\n",
    "    d_model=192 if not USE_SAMPLE else 64,\n",
    "    conv_channels=96 if not USE_SAMPLE else 32,\n",
    "    num_layers=3 if not USE_SAMPLE else 1,\n",
    "    num_heads=8 if not USE_SAMPLE else 4,\n",
    "    d_ff=768 if not USE_SAMPLE else 256,\n",
    "    dropout=0.2,\n",
    "    val_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ig_steps=32 if not USE_SAMPLE else 8,\n",
    "    ig_samples=512 if not USE_SAMPLE else 128,\n",
    "    max_train_samples=500_000 if not USE_SAMPLE else 0,\n",
    ")\n",
    "\n",
    "# ── Enhanced Transformer Config (optimised for T4 GPU) ───────────────\n",
    "enh_cfg = EnhancedConfig(\n",
    "    input_path=DATA_PATH,\n",
    "    output_dir='artifacts',\n",
    "    epochs=35 if not USE_SAMPLE else 5,\n",
    "    batch_size=1024 if not USE_SAMPLE else 64,\n",
    "    val_batch_size=2048 if not USE_SAMPLE else 128,\n",
    "    lr=2e-3,\n",
    "    num_workers=2,\n",
    "    d_model=160 if not USE_SAMPLE else 64,\n",
    "    num_layers=4 if not USE_SAMPLE else 2,\n",
    "    heads=10 if not USE_SAMPLE else 4,\n",
    "    d_ff=640 if not USE_SAMPLE else 256,\n",
    "    dropout=0.15,\n",
    "    group_size=8,\n",
    "    use_swa=True if not USE_SAMPLE else False,\n",
    "    use_mixup=True if not USE_SAMPLE else False,\n",
    "    max_train_samples=500_000 if not USE_SAMPLE else 0,\n",
    ")\n",
    "\n",
    "print(f'Mode: {\"SAMPLE (small model)\" if USE_SAMPLE else \"FULL DATASET (production model)\"}')\n",
    "print(f'Data split: {100*(1-cnn_cfg.val_size-cnn_cfg.test_size):.0f}% train / {100*cnn_cfg.val_size:.0f}% val / {100*cnn_cfg.test_size:.0f}% test')\n",
    "print(f'\\nCNN-Transformer: {cnn_cfg.epochs} epochs, d_model={cnn_cfg.d_model}, batch={cnn_cfg.batch_size}')\n",
    "print(f'Enhanced:        {enh_cfg.epochs} epochs, d_model={enh_cfg.d_model}, batch={enh_cfg.batch_size}')\n",
    "print(f'Max train samples: {cnn_cfg.max_train_samples or \"unlimited\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb7350",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train CNN-Transformer\n",
    "\n",
    "This trains the CNN + Transformer hybrid and automatically generates:\n",
    "- **Integrated Gradients** feature attributions\n",
    "- **Grad-CAM** activation maps over feature positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, time, torch\n",
    "from methun_research.training.cnn_trainer import train_cnn_transformer\n",
    "\n",
    "# Show RAM before training\n",
    "import psutil\n",
    "ram = psutil.virtual_memory()\n",
    "print(f'System RAM: {ram.used/1024**3:.1f} / {ram.total/1024**3:.1f} GB ({ram.percent}% used)')\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'GPU VRAM:   {(total-free)/1024**3:.1f} / {total/1024**3:.1f} GB used')\n",
    "\n",
    "gc.collect()\n",
    "print('\\nTraining CNN-Transformer...')\n",
    "t0 = time.time()\n",
    "cnn_path = train_cnn_transformer(cnn_cfg)\n",
    "\n",
    "elapsed = (time.time() - t0) / 60\n",
    "print(f'\\nDone in {elapsed:.1f} min  ->  {cnn_path}')\n",
    "\n",
    "# Show resource usage after training\n",
    "ram = psutil.virtual_memory()\n",
    "print(f'\\nSystem RAM: {ram.used/1024**3:.1f} / {ram.total/1024**3:.1f} GB ({ram.percent}% used)')\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'GPU VRAM:   {(total-free)/1024**3:.1f} / {total/1024**3:.1f} GB used')\n",
    "    print(f'GPU peak:   {torch.cuda.max_memory_allocated(0)/1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaf657e",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train Enhanced Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ccdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "from methun_research.training.enhanced_trainer import train_enhanced\n",
    "\n",
    "print('Training Enhanced Transformer...')\n",
    "t0 = time.time()\n",
    "enh_path = train_enhanced(enh_cfg)\n",
    "\n",
    "elapsed = (time.time() - t0) / 60\n",
    "print(f'\\nDone in {elapsed:.1f} min  ->  {enh_path}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'GPU VRAM:   {(total-free)/1024**3:.1f} / {total/1024**3:.1f} GB used')\n",
    "    print(f'GPU peak:   {torch.cuda.max_memory_allocated(0)/1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee748358",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. SHAP Analysis — CNN-Transformer\n",
    "\n",
    "Runs `GradientExplainer` on the CNN-Transformer checkpoint.  \n",
    "Produces: global importance CSV, summary beeswarm plot, single-sample waterfall plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd05743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methun_research.interpretability.shap_runner import run_shap\n",
    "\n",
    "os.makedirs('artifacts/shap', exist_ok=True)\n",
    "\n",
    "SHAP_BG   = 2000 if not USE_SAMPLE else 200\n",
    "SHAP_EVAL = 2000 if not USE_SAMPLE else 200\n",
    "SHAP_POOL = 150_000 if not USE_SAMPLE else 500\n",
    "\n",
    "print('Running SHAP on CNN-Transformer...')\n",
    "t0 = time.time()\n",
    "shap_csv = run_shap(\n",
    "    checkpoint_path=cnn_path,\n",
    "    data_path=DATA_PATH,\n",
    "    output_dir='artifacts/shap',\n",
    "    background_size=SHAP_BG,\n",
    "    eval_size=SHAP_EVAL,\n",
    "    eval_pool=SHAP_POOL,\n",
    "    chunk_size=256,\n",
    ")\n",
    "print(f'\\nDone in {(time.time()-t0)/60:.1f} min  ->  {shap_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53f958",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. SHAP Analysis — Enhanced Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b786fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enh_path:\n",
    "    print('Running SHAP on Enhanced Transformer...')\n",
    "    t0 = time.time()\n",
    "    shap_enh_csv = run_shap(\n",
    "        checkpoint_path=enh_path,\n",
    "        data_path=DATA_PATH,\n",
    "        output_dir='artifacts/shap_enhanced',\n",
    "        background_size=SHAP_BG,\n",
    "        eval_size=SHAP_EVAL,\n",
    "        eval_pool=SHAP_POOL,\n",
    "        chunk_size=256,\n",
    "    )\n",
    "    print(f'\\nDone in {(time.time()-t0)/60:.1f} min  ->  {shap_enh_csv}')\n",
    "else:\n",
    "    print('No Enhanced Transformer checkpoint — skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3433bae",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Visualise XAI Results\n",
    "\n",
    "Compare feature rankings across all four XAI methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc65d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "TOP_K = 15\n",
    "\n",
    "def load_ranking(path, val_col, method_name):\n",
    "    if not os.path.exists(path):\n",
    "        print(f'  [{method_name}] Not found: {path}')\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sort_values(val_col, ascending=False).head(TOP_K).reset_index(drop=True)\n",
    "    df.index += 1\n",
    "    df.columns = ['Feature', method_name]\n",
    "    return df\n",
    "\n",
    "rankings = [\n",
    "    load_ranking('artifacts/cnn_transformer_integrated_gradients.csv',\n",
    "                 'avg_abs_integrated_grad', 'Integrated Gradients'),\n",
    "    load_ranking('artifacts/cnn_transformer_grad_cam.csv',\n",
    "                 'grad_cam_importance', 'Grad-CAM'),\n",
    "    load_ranking('artifacts/shap/shap_global_importance_attack.csv',\n",
    "                 'mean_abs_shap', 'SHAP (CNN-Trans)'),\n",
    "]\n",
    "\n",
    "# Enhanced SHAP if available\n",
    "r = load_ranking('artifacts/shap_enhanced/shap_global_importance_attack.csv',\n",
    "                 'mean_abs_shap', 'SHAP (Enhanced)')\n",
    "if r is not None:\n",
    "    rankings.append(r)\n",
    "\n",
    "rankings = [r for r in rankings if r is not None]\n",
    "if rankings:\n",
    "    combined = pd.concat([r.set_index(r.index) for r in rankings], axis=1)\n",
    "    display(HTML(f'<h3>Top {TOP_K} Features — All XAI Methods</h3>'))\n",
    "    display(combined)\n",
    "else:\n",
    "    print('No ranking files found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97613b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plots = [\n",
    "    ('Grad-CAM Feature Importance', 'artifacts/grad_cam_importance.png'),\n",
    "    ('SHAP Summary (CNN-Transformer)', 'artifacts/shap/shap_summary_attack.png'),\n",
    "    ('SHAP Waterfall (CNN-Transformer)', 'artifacts/shap/shap_waterfall_attack.png'),\n",
    "    ('SHAP Summary (Enhanced)', 'artifacts/shap_enhanced/shap_summary_attack.png'),\n",
    "    ('SHAP Waterfall (Enhanced)', 'artifacts/shap_enhanced/shap_waterfall_attack.png'),\n",
    "]\n",
    "\n",
    "for title, path in plots:\n",
    "    if os.path.exists(path):\n",
    "        print(f'\\n--- {title} ---')\n",
    "        display(Image(filename=path, width=700))\n",
    "    else:\n",
    "        print(f'[skip] {title} — file not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b5f18",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Save Artifacts to Google Drive (Optional)\n",
    "\n",
    "Copy all checkpoints and XAI outputs to your Drive for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8439ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save artifacts to Google Drive\n",
    "# import shutil\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "# DEST = '/content/drive/MyDrive/methun_research_artifacts'\n",
    "# shutil.copytree('artifacts', DEST, dirs_exist_ok=True)\n",
    "# print(f'Artifacts saved to {DEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f672f",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. List All Generated Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All generated artifacts:')\n",
    "for root, dirs, files in os.walk('artifacts'):\n",
    "    for f in sorted(files):\n",
    "        fp = os.path.join(root, f)\n",
    "        sz = os.path.getsize(fp)\n",
    "        if sz > 1024*1024:\n",
    "            print(f'  {fp}  ({sz/1024**2:.1f} MB)')\n",
    "        else:\n",
    "            print(f'  {fp}  ({sz/1024:.1f} KB)')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
