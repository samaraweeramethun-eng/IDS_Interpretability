{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6562324b",
   "metadata": {},
   "source": [
    "# Methun Research â€” CNN-Transformer IDS with XAI (Kaggle)\n",
    "\n",
    "This notebook runs the **full pipeline** on Kaggle with a free T4 GPU.\n",
    "\n",
    "| Step | What happens |\n",
    "|------|-------------|\n",
    "| **1. Setup** | Clone repo, install deps, verify GPU |\n",
    "| **2. Data** | Link Kaggle dataset or upload CSV |\n",
    "| **3. Configure** | Set hyperparameters (auto-detects sample vs full) |\n",
    "| **4. CNN-Transformer** | Train hybrid model + IG + Grad-CAM |\n",
    "| **5. Enhanced Transformer** | Train grouped-token model |\n",
    "| **6. SHAP** | GradientExplainer feature importance |\n",
    "| **7. Test Evaluation** | Held-out test set metrics (20% unseen data) |\n",
    "| **8. Results** | Display all XAI outputs side by side |\n",
    "\n",
    "> **Before running:**\n",
    "> 1. Enable **GPU T4 x2** or **GPU P100** via *Settings â†’ Accelerator* (right panel)\n",
    "> 2. Enable **Internet** via *Settings â†’ Internet â†’ On* (needed for git clone + pip)\n",
    "> 3. Add CICIDS2017 as a Kaggle dataset (see Step 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f876a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup â€” Clone & Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, subprocess\n",
    "\n",
    "# â”€â”€ Clone repository â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "REPO_DIR = '/kaggle/working/IDS_Interpretability'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/samaraweeramethun-eng/IDS_Interpretability.git {REPO_DIR}\n",
    "else:\n",
    "    print(f'Repo already exists at {REPO_DIR} â€” pulling latest...')\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "\n",
    "# â”€â”€ Install dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Kaggle already has PyTorch with CUDA, so we only install missing packages\n",
    "!pip install -q shap joblib psutil\n",
    "!pip install -q -e .\n",
    "\n",
    "# â”€â”€ Fallback: add src/ to sys.path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC_DIR = os.path.join(os.getcwd(), 'src')\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "# â”€â”€ Verify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import methun_research\n",
    "print(f'\\nâœ“ methun_research imported from: {methun_research.__file__}')\n",
    "\n",
    "import torch\n",
    "print(f'âœ“ PyTorch {torch.__version__}')\n",
    "print(f'âœ“ CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f'âœ“ GPU {i}: {torch.cuda.get_device_name(i)}')\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'âœ“ VRAM: {total/1024**3:.1f} GB total, {free/1024**3:.1f} GB free')\n",
    "else:\n",
    "    print('âš  WARNING: No GPU detected â€” enable GPU in Settings â†’ Accelerator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5253b0",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data â€” Load CICIDS2017\n",
    "\n",
    "### How to add the dataset on Kaggle:\n",
    "\n",
    "**Option A â€” Use an existing Kaggle dataset:**\n",
    "1. Click **+ Add Data** (right panel) â†’ search `cicids2017`\n",
    "2. Add it â€” the CSV will be at `/kaggle/input/<dataset-name>/cicids2017.csv`\n",
    "3. Update `KAGGLE_DATASET_PATH` below to match\n",
    "\n",
    "**Option B â€” Upload your own CSV as a dataset:**\n",
    "1. Go to [kaggle.com/datasets](https://www.kaggle.com/datasets) â†’ **New Dataset**\n",
    "2. Upload `cicids2017.csv` â†’ create the dataset\n",
    "3. Come back to this notebook â†’ **+ Add Data** â†’ search your dataset name\n",
    "4. Update `KAGGLE_DATASET_PATH` below\n",
    "\n",
    "**Option C â€” Use the included 5,000-row sample (no upload needed):**\n",
    "The sample is already in the repo â€” leave the defaults below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ef1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "# â”€â”€ Update this path to match YOUR Kaggle dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Example: '/kaggle/input/cicids2017-dataset/cicids2017.csv'\n",
    "KAGGLE_DATASET_PATH = ''  # <-- put your path here, or leave empty to auto-detect\n",
    "\n",
    "# â”€â”€ Auto-detection logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_PATH = None\n",
    "\n",
    "# 1. User-specified path\n",
    "if KAGGLE_DATASET_PATH and os.path.exists(KAGGLE_DATASET_PATH):\n",
    "    DATA_PATH = KAGGLE_DATASET_PATH\n",
    "\n",
    "# 2. Search /kaggle/input/ for any cicids CSV\n",
    "if DATA_PATH is None:\n",
    "    candidates = glob.glob('/kaggle/input/**/cicids*.csv', recursive=True)\n",
    "    # Prefer the largest file (likely the full dataset)\n",
    "    if candidates:\n",
    "        candidates.sort(key=os.path.getsize, reverse=True)\n",
    "        DATA_PATH = candidates[0]\n",
    "        print(f'Auto-detected Kaggle dataset: {DATA_PATH}')\n",
    "\n",
    "# 3. Check the repo's data directory\n",
    "if DATA_PATH is None and os.path.exists('data/cicids2017/cicids2017.csv'):\n",
    "    DATA_PATH = 'data/cicids2017/cicids2017.csv'\n",
    "\n",
    "# 4. Fall back to included sample\n",
    "if DATA_PATH is None:\n",
    "    DATA_PATH = 'data/cicids2017/cicids2017_sample.csv'\n",
    "\n",
    "# â”€â”€ Symlink into expected location (so configs work unchanged) â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "repo_data_dir = 'data/cicids2017'\n",
    "os.makedirs(repo_data_dir, exist_ok=True)\n",
    "repo_csv = os.path.join(repo_data_dir, 'cicids2017.csv')\n",
    "if DATA_PATH.startswith('/kaggle/input') and not os.path.exists(repo_csv):\n",
    "    os.symlink(DATA_PATH, repo_csv)\n",
    "    DATA_PATH = repo_csv\n",
    "    print(f'Symlinked Kaggle dataset â†’ {repo_csv}')\n",
    "\n",
    "# â”€â”€ Verify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f'\\nUsing dataset: {DATA_PATH}')\n",
    "print(f'Size: {os.path.getsize(DATA_PATH) / 1024**2:.1f} MB')\n",
    "\n",
    "import pandas as pd\n",
    "df_peek = pd.read_csv(DATA_PATH, nrows=5)\n",
    "print(f'Columns: {len(df_peek.columns)}')\n",
    "label_col = [c for c in df_peek.columns if 'label' in c.lower()][0]\n",
    "counts = pd.read_csv(DATA_PATH, usecols=[label_col])[label_col].value_counts()\n",
    "print(f'\\nLabel distribution:\\n{counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcfd496",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configure Training\n",
    "\n",
    "Hyperparameters are tuned for **Kaggle T4 GPU** (16 GB VRAM, ~13 GB RAM).\n",
    "If you're using the 5,000-row sample, smaller configs are applied automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure methun_research is importable (survives kernel restart)\n",
    "SRC_DIR = os.path.join(os.getcwd(), 'src')\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from methun_research.config import CNNTransformerConfig, EnhancedConfig\n",
    "\n",
    "USE_SAMPLE = 'sample' in DATA_PATH\n",
    "\n",
    "# â”€â”€ CNN-Transformer Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cnn_cfg = CNNTransformerConfig(\n",
    "    input_path=DATA_PATH,\n",
    "    output_dir='/kaggle/working/artifacts',\n",
    "    epochs=25 if not USE_SAMPLE else 5,\n",
    "    batch_size=1024 if not USE_SAMPLE else 64,\n",
    "    val_batch_size=2048 if not USE_SAMPLE else 128,\n",
    "    lr=2e-3 if not USE_SAMPLE else 1.5e-3,\n",
    "    num_workers=2,\n",
    "    d_model=192 if not USE_SAMPLE else 64,\n",
    "    conv_channels=96 if not USE_SAMPLE else 32,\n",
    "    num_layers=3 if not USE_SAMPLE else 1,\n",
    "    num_heads=8 if not USE_SAMPLE else 4,\n",
    "    d_ff=768 if not USE_SAMPLE else 256,\n",
    "    dropout=0.2,\n",
    "    val_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ig_steps=32 if not USE_SAMPLE else 8,\n",
    "    ig_samples=512 if not USE_SAMPLE else 128,\n",
    "    max_train_samples=500_000 if not USE_SAMPLE else 0,\n",
    ")\n",
    "\n",
    "# â”€â”€ Enhanced Transformer Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "enh_cfg = EnhancedConfig(\n",
    "    input_path=DATA_PATH,\n",
    "    output_dir='/kaggle/working/artifacts',\n",
    "    epochs=35 if not USE_SAMPLE else 5,\n",
    "    batch_size=1024 if not USE_SAMPLE else 64,\n",
    "    val_batch_size=2048 if not USE_SAMPLE else 128,\n",
    "    lr=2e-3,\n",
    "    num_workers=2,\n",
    "    d_model=160 if not USE_SAMPLE else 64,\n",
    "    num_layers=4 if not USE_SAMPLE else 2,\n",
    "    heads=10 if not USE_SAMPLE else 4,\n",
    "    d_ff=640 if not USE_SAMPLE else 256,\n",
    "    dropout=0.15,\n",
    "    group_size=8,\n",
    "    use_swa=True if not USE_SAMPLE else False,\n",
    "    use_mixup=True if not USE_SAMPLE else False,\n",
    "    max_train_samples=500_000 if not USE_SAMPLE else 0,\n",
    ")\n",
    "\n",
    "print(f'Mode: {\"SAMPLE (small model)\" if USE_SAMPLE else \"FULL DATASET (production model)\"}')\n",
    "print(f'Data split: {100*(1-cnn_cfg.val_size-cnn_cfg.test_size):.0f}% train / {100*cnn_cfg.val_size:.0f}% val / {100*cnn_cfg.test_size:.0f}% test')\n",
    "print(f'\\nCNN-Transformer: {cnn_cfg.epochs} epochs, d_model={cnn_cfg.d_model}, batch={cnn_cfg.batch_size}')\n",
    "print(f'Enhanced:        {enh_cfg.epochs} epochs, d_model={enh_cfg.d_model}, batch={enh_cfg.batch_size}')\n",
    "print(f'Max train samples: {cnn_cfg.max_train_samples or \"unlimited\"}')\n",
    "print(f'Output dir: {cnn_cfg.output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ed2eb",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train CNN-Transformer\n",
    "\n",
    "Trains the CNN + Transformer hybrid and automatically generates:\n",
    "- **Integrated Gradients** feature attributions\n",
    "- **Grad-CAM** activation maps over feature positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e501777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, time, torch\n",
    "from methun_research.training.cnn_trainer import train_cnn_transformer\n",
    "\n",
    "# Show resources before training\n",
    "import psutil\n",
    "ram = psutil.virtual_memory()\n",
    "print(f'System RAM: {ram.used/1024**3:.1f} / {ram.total/1024**3:.1f} GB ({ram.percent}% used)')\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'GPU VRAM:   {(total-free)/1024**3:.1f} / {total/1024**3:.1f} GB used')\n",
    "\n",
    "os.makedirs(cnn_cfg.output_dir, exist_ok=True)\n",
    "gc.collect()\n",
    "print('\\nTraining CNN-Transformer...')\n",
    "t0 = time.time()\n",
    "cnn_path = train_cnn_transformer(cnn_cfg)\n",
    "\n",
    "elapsed = (time.time() - t0) / 60\n",
    "print(f'\\nâœ“ Done in {elapsed:.1f} min â†’ {cnn_path}')\n",
    "\n",
    "# Show resources after training\n",
    "ram = psutil.virtual_memory()\n",
    "print(f'\\nSystem RAM: {ram.used/1024**3:.1f} / {ram.total/1024**3:.1f} GB ({ram.percent}% used)')\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'GPU VRAM:   {(total-free)/1024**3:.1f} / {total/1024**3:.1f} GB used')\n",
    "    print(f'GPU peak:   {torch.cuda.max_memory_allocated(0)/1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429e8b6",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train Enhanced Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a19b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "from methun_research.training.enhanced_trainer import train_enhanced\n",
    "\n",
    "print('Training Enhanced Transformer...')\n",
    "t0 = time.time()\n",
    "enh_path = train_enhanced(enh_cfg)\n",
    "\n",
    "elapsed = (time.time() - t0) / 60\n",
    "print(f'\\nâœ“ Done in {elapsed:.1f} min â†’ {enh_path}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    free, total = torch.cuda.mem_get_info(0)\n",
    "    print(f'GPU VRAM:   {(total-free)/1024**3:.1f} / {total/1024**3:.1f} GB used')\n",
    "    print(f'GPU peak:   {torch.cuda.max_memory_allocated(0)/1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cc631",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. SHAP Analysis â€” CNN-Transformer\n",
    "\n",
    "Runs `GradientExplainer` on the CNN-Transformer checkpoint.\n",
    "Produces: global importance CSV, summary beeswarm plot, single-sample waterfall plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "from methun_research.interpretability.shap_runner import run_shap\n",
    "\n",
    "SHAP_BG   = 2000 if not USE_SAMPLE else 200\n",
    "SHAP_EVAL = 2000 if not USE_SAMPLE else 200\n",
    "SHAP_POOL = 150_000 if not USE_SAMPLE else 500\n",
    "\n",
    "shap_dir = os.path.join(cnn_cfg.output_dir, 'shap')\n",
    "os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "print('Running SHAP on CNN-Transformer...')\n",
    "t0 = time.time()\n",
    "shap_csv = run_shap(\n",
    "    checkpoint_path=cnn_path,\n",
    "    data_path=DATA_PATH,\n",
    "    output_dir=shap_dir,\n",
    "    background_size=SHAP_BG,\n",
    "    eval_size=SHAP_EVAL,\n",
    "    eval_pool=SHAP_POOL,\n",
    "    chunk_size=256,\n",
    ")\n",
    "print(f'\\nâœ“ Done in {(time.time()-t0)/60:.1f} min â†’ {shap_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c43a9",
   "metadata": {},
   "source": [
    "---\n",
    "## 6b. SHAP Analysis â€” Enhanced Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e041136",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if enh_path:\n",
    "    shap_enh_dir = os.path.join(enh_cfg.output_dir, 'shap_enhanced')\n",
    "    os.makedirs(shap_enh_dir, exist_ok=True)\n",
    "    print('Running SHAP on Enhanced Transformer...')\n",
    "    t0 = time.time()\n",
    "    shap_enh_csv = run_shap(\n",
    "        checkpoint_path=enh_path,\n",
    "        data_path=DATA_PATH,\n",
    "        output_dir=shap_enh_dir,\n",
    "        background_size=SHAP_BG,\n",
    "        eval_size=SHAP_EVAL,\n",
    "        eval_pool=SHAP_POOL,\n",
    "        chunk_size=256,\n",
    "    )\n",
    "    print(f'\\nâœ“ Done in {(time.time()-t0)/60:.1f} min â†’ {shap_enh_csv}')\n",
    "else:\n",
    "    print('No Enhanced Transformer checkpoint â€” skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0bbd2",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Test Set Evaluation Summary\n",
    "\n",
    "Both trainers automatically evaluate on a **held-out 20% test set** that is never seen during training or validation.\n",
    "This cell loads the saved test metrics from each checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "OUT = cnn_cfg.output_dir\n",
    "\n",
    "def load_test_metrics(ckpt_path, model_name):\n",
    "    if not ckpt_path or not os.path.exists(ckpt_path):\n",
    "        print(f'  [{model_name}] Checkpoint not found')\n",
    "        return None\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "    m = ckpt.get('test_metrics')\n",
    "    if not m:\n",
    "        print(f'  [{model_name}] No test_metrics in checkpoint')\n",
    "        return None\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'ROC-AUC': f\"{m['auc_roc']:.4f}\",\n",
    "        'PR-AUC': f\"{m['auc_pr']:.4f}\",\n",
    "        'F1-Score': f\"{m['f1_score']:.4f}\",\n",
    "        'Precision': f\"{m['precision']:.4f}\",\n",
    "        'Recall': f\"{m['recall']:.4f}\",\n",
    "        'Accuracy': f\"{m['accuracy']:.4f}\",\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "r = load_test_metrics(cnn_path, 'CNN-Transformer')\n",
    "if r: rows.append(r)\n",
    "r = load_test_metrics(enh_path, 'Enhanced Transformer')\n",
    "if r: rows.append(r)\n",
    "\n",
    "if rows:\n",
    "    df_test = pd.DataFrame(rows).set_index('Model')\n",
    "    display(HTML('<h3>ðŸ§ª Held-Out Test Set Results (20% of data, never seen during training)</h3>'))\n",
    "    display(df_test)\n",
    "else:\n",
    "    print('No test metrics available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82530f",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Visualise XAI Results\n",
    "\n",
    "Compare feature rankings across all four XAI methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "OUT = cnn_cfg.output_dir\n",
    "TOP_K = 15\n",
    "\n",
    "def load_ranking(path, val_col, method_name):\n",
    "    if not os.path.exists(path):\n",
    "        print(f'  [{method_name}] Not found: {path}')\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sort_values(val_col, ascending=False).head(TOP_K).reset_index(drop=True)\n",
    "    df.index += 1\n",
    "    df.columns = ['Feature', method_name]\n",
    "    return df\n",
    "\n",
    "rankings = [\n",
    "    load_ranking(f'{OUT}/cnn_transformer_integrated_gradients.csv',\n",
    "                 'avg_abs_integrated_grad', 'Integrated Gradients'),\n",
    "    load_ranking(f'{OUT}/cnn_transformer_grad_cam.csv',\n",
    "                 'grad_cam_importance', 'Grad-CAM'),\n",
    "    load_ranking(f'{OUT}/shap/shap_global_importance_attack.csv',\n",
    "                 'mean_abs_shap', 'SHAP (CNN-Trans)'),\n",
    "]\n",
    "\n",
    "r = load_ranking(f'{OUT}/shap_enhanced/shap_global_importance_attack.csv',\n",
    "                 'mean_abs_shap', 'SHAP (Enhanced)')\n",
    "if r is not None:\n",
    "    rankings.append(r)\n",
    "\n",
    "rankings = [r for r in rankings if r is not None]\n",
    "if rankings:\n",
    "    combined = pd.concat([r.set_index(r.index) for r in rankings], axis=1)\n",
    "    display(HTML(f'<h3>Top {TOP_K} Features â€” All XAI Methods</h3>'))\n",
    "    display(combined)\n",
    "else:\n",
    "    print('No ranking files found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f22d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "OUT = cnn_cfg.output_dir\n",
    "plots = [\n",
    "    ('Grad-CAM Feature Importance', f'{OUT}/grad_cam_importance.png'),\n",
    "    ('SHAP Summary (CNN-Transformer)', f'{OUT}/shap/shap_summary_attack.png'),\n",
    "    ('SHAP Waterfall (CNN-Transformer)', f'{OUT}/shap/shap_waterfall_attack.png'),\n",
    "    ('SHAP Summary (Enhanced)', f'{OUT}/shap_enhanced/shap_summary_attack.png'),\n",
    "    ('SHAP Waterfall (Enhanced)', f'{OUT}/shap_enhanced/shap_waterfall_attack.png'),\n",
    "]\n",
    "\n",
    "for title, path in plots:\n",
    "    if os.path.exists(path):\n",
    "        print(f'\\n--- {title} ---')\n",
    "        display(Image(filename=path, width=700))\n",
    "    else:\n",
    "        print(f'[skip] {title} â€” file not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a6bfa",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. List All Generated Artifacts\n",
    "\n",
    "Everything in `/kaggle/working/artifacts/` is automatically saved as notebook output.\n",
    "Click **Output** tab (right panel) â†’ **Download All** to get the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff87dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = cnn_cfg.output_dir\n",
    "print(f'All generated artifacts in {OUT}:')\n",
    "total_size = 0\n",
    "for root, dirs, files in os.walk(OUT):\n",
    "    for f in sorted(files):\n",
    "        fp = os.path.join(root, f)\n",
    "        sz = os.path.getsize(fp)\n",
    "        total_size += sz\n",
    "        if sz > 1024*1024:\n",
    "            print(f'  {os.path.relpath(fp, OUT)}  ({sz/1024**2:.1f} MB)')\n",
    "        else:\n",
    "            print(f'  {os.path.relpath(fp, OUT)}  ({sz/1024:.1f} KB)')\n",
    "print(f'\\nTotal: {total_size/1024**2:.1f} MB')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
